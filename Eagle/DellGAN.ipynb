{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rCGXkZjkxbMg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZEFFjiznnXTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9592e3d-3bdc-414c-c120-cbf82c6362cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "real = np.load('/content/drive/MyDrive/Footprints Datasets/real.npz')\n",
        "fake = np.load('/content/drive/MyDrive/Footprints Datasets/fake.npz')"
      ],
      "metadata": {
        "id": "3FxjEt_vxkWB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake"
      ],
      "metadata": {
        "id": "tmS-VMjmn9gG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df14722-3bef-4d55-bb9c-f5f64292f590"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NpzFile '/content/drive/MyDrive/Footprints Datasets/fake.npz' with keys: x, y"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real.files\n",
        "real['y'].shape\n"
      ],
      "metadata": {
        "id": "WnL4YQfix7zP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc37533-8d1e-4f27-cf0f-065c62f7a695"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 496)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real['x'].shape"
      ],
      "metadata": {
        "id": "qeIHFKa5pmit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a44a719-e6f0-484c-b9e6-d7bf20ba7dfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 1998, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake['x'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQeueObax9fb",
        "outputId": "ab2f9f46-12ef-4661-81d6-0127f76b9cd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 1998, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4"
      ],
      "metadata": {
        "id": "Pflt_l3opw4I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "0bacce74-0034-49e2-be88-ff72709b3cde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b5fd2be6392>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform = transforms.Compose(\n\u001b[0m\u001b[1;32m      2\u001b[0m     [transforms.ToTensor(),\n\u001b[1;32m      3\u001b[0m      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(real['x'][2][728])"
      ],
      "metadata": {
        "id": "Q6Kj3HsDD5CH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10d0b61-6a3c-4a95-cc61-4d6c753841c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.3680e+04 3.2576e+04        inf 5.0848e+04 4.3280e+03 1.6288e+02\n",
            " 1.0450e+02 8.6188e+01 1.9094e+01 1.2742e+01 1.5025e+02 9.2400e+02\n",
            " 1.4210e+03 4.8675e+02 1.8156e+01 1.2050e+02 3.2650e+02 5.8550e+02\n",
            " 5.1100e+02 1.3300e+02 5.0812e+01 5.6156e+01 2.0662e+02 4.0025e+02\n",
            " 5.9500e+02 9.9300e+02 9.2450e+02 4.4375e+02 6.4625e+01 1.8016e+01\n",
            " 3.2844e+01 6.0281e+01 5.4188e+01 6.5062e+01 1.4047e+01 6.5391e+00\n",
            " 4.2688e+01 7.7000e+01 1.9594e+01 1.9873e-01 2.4648e+00 1.8496e+00\n",
            " 3.0312e+00 7.0264e-01 1.3574e+00 1.4180e+00 9.9170e-01 4.6143e-01\n",
            " 1.8398e+00 3.6367e+00 4.3384e-01 8.7939e-01 2.3652e+00 1.1475e+00\n",
            " 5.1562e+00 1.6904e+00 1.0068e+00 7.1973e-01 2.0972e-01 1.1563e-05\n",
            " 1.9019e-01 2.1692e-01 2.2949e-01 7.1472e-02 6.5491e-02 3.0005e-01\n",
            " 2.0728e-01 1.1279e-01 4.5319e-02 3.1860e-01 3.4375e-01 2.8735e-01\n",
            " 3.8794e-01 5.9277e-01 2.9388e-02 1.4001e-01 1.3391e-01 9.0918e-01\n",
            " 7.6025e-01 1.1749e-01 2.9590e-01 7.9346e-01 2.9590e-01 8.5449e-02\n",
            " 1.6699e-01 6.2256e-02 1.4107e-02 4.9164e-02 4.9377e-02 2.3682e-02\n",
            " 2.9850e-03 1.7548e-02 1.9882e-02 4.4067e-02 5.9998e-02 5.3955e-02\n",
            " 9.5337e-02 1.0815e-01 2.0544e-01 9.4727e-02 2.0984e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52I8Chw-2mwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: take the real['y'] and return for every entry a tuple consisting the index of the first and last occurence of one and store in a new numpy array called modifiied_y\n",
        "\n",
        "import numpy as np\n",
        "modified_y = np.zeros((real['y'].shape[0], 2))\n",
        "for i in range(real['y'].shape[0]):\n",
        "  index_first = np.where(real['y'][i] == 1)[0][0]\n",
        "  index_last = np.where(real['y'][i] == 1)[0][-1]\n",
        "  modified_y[i] = [index_first, index_last]\n",
        "\n",
        "print(modified_y[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow89fbTjGR69",
        "outputId": "67bc2bdd-3e97-4a5b-e7d7-4347cddfb35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[122. 220.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_sample = fake['y'][0]\n",
        "\n",
        "print(np.unique(fake['y']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47pveEPHw1-",
        "outputId": "f9be4c8a-6114-456d-d4de-74cf920d2845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ],
      "metadata": {
        "id": "vU1dYXQ1oYda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a CNN model with 1 CNN layer, 1 max pooling, 1 CNN, 1 dense layer and an output of 496 nodes using tensorflow keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=(real['x'].shape[1], real['x'].shape[2], 1))\n",
        "\n",
        "# Add the first CNN layer\n",
        "conv1 = Conv2D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
        "\n",
        "# Add the max pooling layer\n",
        "pool1 = MaxPooling2D(pool_size=2)(conv1)\n",
        "\n",
        "# Add the second CNN layer\n",
        "conv2 = Conv2D(filters=32, kernel_size=4, activation='relu')(pool1)\n",
        "\n",
        "# Add the max pooling layer\n",
        "pool2 = MaxPooling2D(pool_size=3)(conv2)\n",
        "\n",
        "# Add the second CNN layer\n",
        "conv3 = Conv2D(filters=64, kernel_size=4, activation='relu')(pool2)\n",
        "\n",
        "# Add the max pooling layer\n",
        "pool3 = MaxPooling2D(pool_size=3)(conv3)\n",
        "\n",
        "# Flatten the output of the CNN layers\n",
        "flattened = Flatten()(pool3)\n",
        "\n",
        "\n",
        "dense1 = Dense(128, activation='relu')(flattened)\n",
        "\n",
        "# Add the dense layer\n",
        "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=dense2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5H_5BMYEX9N",
        "outputId": "f46af05e-d946-46c4-a0db-6782e7ce8fe7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1998, 101, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 1996, 99, 16)      160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 998, 49, 16)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 995, 46, 32)       8224      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 331, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 328, 12, 64)       32832     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 109, 4, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 27904)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3571840   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3613185 (13.78 MB)\n",
            "Trainable params: 3613185 (13.78 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.isinf(real['x']) == True)"
      ],
      "metadata": {
        "id": "EtS_h1p_dxZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee0816-466b-4a77-afa0-7da9c6ee097d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  2,   2,   2, ..., 749, 749, 749]),\n",
              " array([728, 732, 732, ..., 423, 423, 428]),\n",
              " array([2, 1, 2, ..., 2, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train the model on real['x'] and fake['x] with the labels being 1 for real and 0 for fake\n",
        "\n",
        "import numpy as np\n",
        "# Prepare the training data\n",
        "value = 65470.0\n",
        "\n",
        "real_x = real['x']\n",
        "fake_x = fake['x']\n",
        "\n",
        "real_x = np.nan_to_num(real_x, value)\n",
        "fake_x = np.nan_to_num(fake_x, value)\n",
        "\n",
        "\n",
        "# Prepare the training labels\n",
        "real_y = np.ones((real_x.shape[0], 1))\n",
        "fake_y = np.zeros((fake_x.shape[0], 1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2LWXTpMFi2z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: standardize the datasets\n",
        "\n",
        "import numpy as np\n",
        "# Standardize the real and fake datasets\n",
        "mean_real = np.mean(real_x, axis=0)\n",
        "print(mean_real)\n",
        "std_real = np.std(real_x, axis=0)\n",
        "print(std_real)\n",
        "real_x = (real_x - mean_real) / std_real\n",
        "\n",
        "mean_fake = np.mean(fake_x, axis=0)\n",
        "std_fake = np.std(fake_x, axis=0)\n",
        "fake_x = (fake_x - mean_fake) / std_fake\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDSu-HAGQSMC",
        "outputId": "cca0374d-7534-4709-e767-3fa3498381a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.4617e-02 6.1066e-02 2.7023e-02 ... 4.0174e-05 1.1456e-04 9.5367e-05]\n",
            " [5.8228e-02 1.4014e-01 4.8126e-02 ... 1.4734e-04 2.4116e-04 1.0449e-04]\n",
            " [4.8332e-03 1.9318e-02 1.9379e-02 ... 8.1658e-06 3.4511e-05 3.5226e-05]\n",
            " ...\n",
            " [9.1003e-02 3.9990e-01 3.3228e-01 ... 3.1471e-05 4.0948e-05 4.5598e-05]\n",
            " [2.6318e-01 1.9910e-01 3.8574e-01 ... 2.3603e-05 4.0174e-05 4.7565e-05]\n",
            " [2.1973e-02 5.3467e-02 8.9050e-02 ... 3.0935e-05 5.4240e-05 5.0306e-05]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:152: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.647e-01 1.178e+00 5.259e-01 ... 8.459e-04 2.630e-03 2.264e-03]\n",
            " [1.575e+00 3.611e+00 1.249e+00 ... 4.005e-03 6.126e-03 2.197e-03]\n",
            " [8.881e-02 3.640e-01 4.697e-01 ... 0.000e+00 6.461e-04 6.905e-04]\n",
            " ...\n",
            " [2.312e-01 1.079e+00 8.184e-01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [7.598e-01 5.767e-01 1.128e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [3.180e-02 1.128e-01 1.812e-01 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-56a831b1df9b>:9: RuntimeWarning: divide by zero encountered in divide\n",
            "  real_x = (real_x - mean_real) / std_real\n",
            "<ipython-input-21-56a831b1df9b>:9: RuntimeWarning: invalid value encountered in divide\n",
            "  real_x = (real_x - mean_real) / std_real\n",
            "<ipython-input-21-56a831b1df9b>:13: RuntimeWarning: divide by zero encountered in divide\n",
            "  fake_x = (fake_x - mean_fake) / std_fake\n",
            "<ipython-input-21-56a831b1df9b>:13: RuntimeWarning: invalid value encountered in divide\n",
            "  fake_x = (fake_x - mean_fake) / std_fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_x[0][0]"
      ],
      "metadata": {
        "id": "6wWJtBkT3vSp",
        "outputId": "fed3d691-5e46-435f-f331-be9d2bbb3f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0516 , -0.05185, -0.0514 , -0.05118, -0.0517 , -0.03766,\n",
              "       -0.0381 , -0.0377 , -0.03748, -0.03754, -0.03665, -0.05182,\n",
              "       -0.04968, -0.04916, -0.05084, -0.04565, -0.0437 , -0.04102,\n",
              "       -0.03848, -0.04147, -0.03683, -0.03714, -0.03748, -0.0371 ,\n",
              "       -0.04373, -0.03793, -0.0453 , -0.0427 , -0.0369 , -0.03827,\n",
              "       -0.04022, -0.03995, -0.05127, -0.05045, -0.03857, -0.04242,\n",
              "       -0.0431 , -0.0453 , -0.05127, -0.04108, -0.04013, -0.03677,\n",
              "       -0.04166, -0.0451 , -0.05078, -0.05072, -0.05035, -0.0394 ,\n",
              "       -0.04163, -0.0603 , -0.04303, -0.03723, -0.0455 , -0.0515 ,\n",
              "       -0.04007, -0.04156, -0.04422, -0.046  , -0.0403 , -0.03925,\n",
              "       -0.0429 , -0.03888, -0.0387 , -0.0397 , -0.03897, -0.04178,\n",
              "       -0.03842, -0.0487 , -0.051  , -0.05176, -0.0516 , -0.045  ,\n",
              "       -0.04788, -0.05176, -0.0476 , -0.0512 , -0.04913, -0.04944,\n",
              "       -0.05063, -0.05014, -0.04974, -0.05063, -0.05017, -0.04233,\n",
              "       -0.04144, -0.0489 , -0.05066, -0.0441 , -0.0513 , -0.04883,\n",
              "       -0.04874, -0.0444 , -0.0433 , -0.0394 , -0.0471 , -0.04028,\n",
              "       -0.03726, -0.03967, -0.0475 , -0.04355, -0.0421 ], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a numpy array\n",
        "arr2 = real_x\n",
        "\n",
        "# Find the maximum value\n",
        "max_value = np.max(arr2)\n",
        "print(max_value)\n",
        "\n",
        "# Replace the maximum value with negative infinity\n",
        "arr2[arr2 == max_value] = -np.inf\n",
        "\n",
        "# Find the second maximum value\n",
        "second_max_value = np.max(arr2)\n",
        "\n",
        "# print(\"Original array:\", arr2)\n",
        "print(\"Second maximum value:\", second_max_value)\n"
      ],
      "metadata": {
        "id": "y2e2PZ2H3rGD",
        "outputId": "72183b92-8194-43d4-9357-bcded152dfb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "Second maximum value: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train the model on real['x'] and fake['x] with the labels being 1 for real and 0 for fake\n",
        "\n",
        "import numpy as np\n",
        "# Prepare the training data\n",
        "value = 0\n",
        "\n",
        "real_x = np.nan_to_num(real_x, value)\n",
        "fake_x = np.nan_to_num(fake_x, value)\n",
        "\n",
        "\n",
        "# Prepare the training labels\n",
        "real_y = np.ones((real_x.shape[0], 1))\n",
        "fake_y = np.zeros((fake_x.shape[0], 1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uBgTfQdA3V67"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(real_x[5][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3cREAOEWePv",
        "outputId": "89ffa514-1084-4727-d61c-e0fc233196d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.685e-02 -4.166e-02 -3.860e-02 -3.769e-02 -3.760e-02 -3.668e-02\n",
            " -3.870e-02 -3.775e-02 -4.706e-02 -4.062e-02 -3.812e-02 -3.964e-02\n",
            " -4.895e-02 -3.918e-02 -4.285e-02 -4.199e-02 -4.147e-02 -4.056e-02\n",
            " -4.102e-02 -3.815e-02 -3.683e-02 -3.680e-02 -3.687e-02 -3.680e-02\n",
            " -3.708e-02 -3.674e-02 -3.665e-02 -3.772e-02 -3.775e-02 -4.114e-02\n",
            " -3.821e-02 -3.979e-02 -4.587e-02 -4.034e-02 -3.839e-02 -3.809e-02\n",
            " -4.327e-02 -3.729e-02 -3.766e-02 -3.854e-02 -3.836e-02 -3.790e-02\n",
            " -5.283e-02 -4.947e-02 -4.980e-02 -4.092e-02 -3.888e-02 -3.821e-02\n",
            " -4.486e-02 -5.219e-02 -5.423e-02 -5.148e-02 -3.879e-02 -4.089e-02\n",
            " -5.380e-02 -3.897e-02 -4.214e-02 -4.706e-02 -5.377e-02 -5.185e-02\n",
            " -5.127e-02 -5.203e-02 -4.297e-02 -3.857e-02 -6.550e+04 -3.778e-02\n",
            " -3.955e-02 -4.395e-02 -6.550e+04 -4.086e-02 -4.395e-02 -5.341e-02\n",
            " -5.249e-02 -5.048e-02 -5.310e-02 -4.385e-02 -4.880e-02 -5.737e-02\n",
            " -5.087e-02 -4.504e-02 -3.802e-02 -4.056e-02 -4.749e-02 -6.550e+04\n",
            " -5.542e-02 -4.935e-02 -6.750e-02 -8.545e-02 -5.142e-02 -4.745e-02\n",
            " -3.644e-02 -3.693e-02 -4.858e-02 -6.550e+04 -4.282e-02 -6.550e+04\n",
            " -6.550e+04 -6.550e+04 -6.550e+04 -4.910e-02 -4.910e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: split the dataset using real_x, fake_x, real_y, fake_y\n",
        "\n",
        "import numpy as np\n",
        "# Split the dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "real_x_train, real_x_test, real_y_train, real_y_test = train_test_split(real_x, real_y, test_size=0.2)\n",
        "fake_x_train, fake_x_test, fake_y_train, fake_y_test = train_test_split(fake_x, fake_y, test_size=0.2)\n",
        "\n",
        "# Combine the training data\n",
        "x_train = np.concatenate((real_x_train, fake_x_train))\n",
        "y_train = np.concatenate((real_y_train, fake_y_train))\n",
        "\n",
        "# Combine the test data\n",
        "x_test = np.concatenate((real_x_test, fake_x_test))\n",
        "y_test = np.concatenate((real_y_test, fake_y_test))\n"
      ],
      "metadata": {
        "id": "3a3reI8SJQHS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.isinf(x_train) == True)"
      ],
      "metadata": {
        "id": "OCSioFoW4iEv",
        "outputId": "cadbbfef-9e51-4831-add9-11468c7f17aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the real and fake data\n",
        "x_train = np.concatenate((real_x, fake_x), axis=0)\n",
        "y_train = np.concatenate((real_y, fake_y), axis=0)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc-2Z3ecJPUG",
        "outputId": "7d2e2bb0-dfc3-4b8b-d05f-85c116a113c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "47/47 [==============================] - 13s 126ms/step - loss: nan - accuracy: 0.5040\n",
            "Epoch 2/10\n",
            "47/47 [==============================] - 4s 78ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "47/47 [==============================] - 4s 78ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.6932 - accuracy: 0.4813\n",
            "Epoch 6/10\n",
            "47/47 [==============================] - 4s 80ms/step - loss: 0.6932 - accuracy: 0.4880\n",
            "Epoch 7/10\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.6932 - accuracy: 0.4867\n",
            "Epoch 8/10\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.6932 - accuracy: 0.4827\n",
            "Epoch 9/10\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.6932 - accuracy: 0.4840\n",
            "Epoch 10/10\n",
            "47/47 [==============================] - 4s 80ms/step - loss: 0.6932 - accuracy: 0.4667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6dbe6dfca0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a new reshaped X_train that is 2D (name it xgboost_x_train)\n",
        "\n",
        "xgboost_x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n"
      ],
      "metadata": {
        "id": "Yp4lDmFARtCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create an XGBoost classifier for real_x and fake_x\n",
        "\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Create the XGBoost classifier\n",
        "xgb_classifier = XGBClassifier()\n",
        "\n",
        "# Train the XGBoost classifier on the real and fake data\n",
        "xgb_classifier.fit(xgboost_x_train, y_train)\n"
      ],
      "metadata": {
        "id": "afTEDRFKJg1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "4FwR1Qqwgyn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use torch.Dataloader on x_train, x_test, y_train, y_test\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "i1s2NEHfhoqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset =\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "POgGJIlmgzTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(16, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(10912 , 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "DjGvk2L7Rpfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "b_czkQwXe26v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        input_tensor = inputs.to(dtype=torch.float)\n",
        "        labels = labels.squeeze().long()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(input_tensor)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "8zlXgEqce4Rv",
        "outputId": "a4afcc63-9a82-4413-c423-1e9beaef267e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [6, 16, 5, 5], expected input[1, 12, 1998, 101] to have 16 channels, but got 12 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-e99cd626218a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-4ddb33b401cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 16, 5, 5], expected input[1, 12, 1998, 101] to have 16 channels, but got 12 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Convert the data to a flat 2D shape\n",
        "X_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "X_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# Create Gradient Boosting classifier\n",
        "model = GradientBoostingClassifier(random_state=42, verbose=True)\n",
        "# Train the model\n",
        "model.fit(X_train_flat, y_train.ravel())\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_flat)\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"&quot;Accuracy: {:.4f}&quot;\".format(accuracy))\n",
        "print(\"&quot;F1 score: {:.4f}&quot;\".format(f1))\n"
      ],
      "metadata": {
        "id": "8MlwuXtXiHyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "ce710468-a010-43ff-e486-280350e15d94"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1963           28.85m\n",
            "         2           1.0407           28.32m\n",
            "         3           0.9109           34.95m\n",
            "         4           0.8012           32.74m\n",
            "         5           0.7075           35.74m\n",
            "         6           0.6268           37.69m\n",
            "         7           0.5568           38.33m\n",
            "         8           0.4957           38.81m\n",
            "         9           0.4422           39.26m\n",
            "        10           0.3951           38.07m\n",
            "        20           0.1355           31.41m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-45da2479accc>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(real['x'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugfmCF6aqF1b",
        "outputId": "83bbe2a5-2a12-42b2-dd80-9c27d26888e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(real['x'])\n",
        "indices = np.where(np.isinf(arr))\n",
        "print(\"Infinite values:\", indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpKEhzW9qwuH",
        "outputId": "d5bbe757-7a8d-4c96-c509-716a2f3078ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infinite values: (array([  2,   2,   2, ..., 749, 749, 749]), array([728, 732, 732, ..., 423, 423, 428]), array([2, 1, 2, ..., 2, 3, 3]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr[2][728]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHtlOdLjrppG",
        "outputId": "7bef97f0-e6f0-4805-ebd5-cb72ce9e5361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.3680e+04, 3.2576e+04,        inf, 5.0848e+04, 4.3280e+03,\n",
              "       1.6288e+02, 1.0450e+02, 8.6188e+01, 1.9094e+01, 1.2742e+01,\n",
              "       1.5025e+02, 9.2400e+02, 1.4210e+03, 4.8675e+02, 1.8156e+01,\n",
              "       1.2050e+02, 3.2650e+02, 5.8550e+02, 5.1100e+02, 1.3300e+02,\n",
              "       5.0812e+01, 5.6156e+01, 2.0662e+02, 4.0025e+02, 5.9500e+02,\n",
              "       9.9300e+02, 9.2450e+02, 4.4375e+02, 6.4625e+01, 1.8016e+01,\n",
              "       3.2844e+01, 6.0281e+01, 5.4188e+01, 6.5062e+01, 1.4047e+01,\n",
              "       6.5391e+00, 4.2688e+01, 7.7000e+01, 1.9594e+01, 1.9873e-01,\n",
              "       2.4648e+00, 1.8496e+00, 3.0312e+00, 7.0264e-01, 1.3574e+00,\n",
              "       1.4180e+00, 9.9170e-01, 4.6143e-01, 1.8398e+00, 3.6367e+00,\n",
              "       4.3384e-01, 8.7939e-01, 2.3652e+00, 1.1475e+00, 5.1562e+00,\n",
              "       1.6904e+00, 1.0068e+00, 7.1973e-01, 2.0972e-01, 1.1563e-05,\n",
              "       1.9019e-01, 2.1692e-01, 2.2949e-01, 7.1472e-02, 6.5491e-02,\n",
              "       3.0005e-01, 2.0728e-01, 1.1279e-01, 4.5319e-02, 3.1860e-01,\n",
              "       3.4375e-01, 2.8735e-01, 3.8794e-01, 5.9277e-01, 2.9388e-02,\n",
              "       1.4001e-01, 1.3391e-01, 9.0918e-01, 7.6025e-01, 1.1749e-01,\n",
              "       2.9590e-01, 7.9346e-01, 2.9590e-01, 8.5449e-02, 1.6699e-01,\n",
              "       6.2256e-02, 1.4107e-02, 4.9164e-02, 4.9377e-02, 2.3682e-02,\n",
              "       2.9850e-03, 1.7548e-02, 1.9882e-02, 4.4067e-02, 5.9998e-02,\n",
              "       5.3955e-02, 9.5337e-02, 1.0815e-01, 2.0544e-01, 9.4727e-02,\n",
              "       2.0984e-01], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 65470.0\n",
        "\n",
        "x_train[np.isinf(x_train)] = np.nan  # Replace infinite with NaN\n",
        "x_train = np.nan_to_num(x_train, value)\n"
      ],
      "metadata": {
        "id": "5i5XY6MqsCNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a numpy array\n",
        "arr2 = np.array(real['x'])\n",
        "\n",
        "# Find the maximum value\n",
        "max_value = np.max(arr2)\n",
        "\n",
        "# Replace the maximum value with negative infinity\n",
        "arr2[arr2 == max_value] = -np.inf\n",
        "\n",
        "# Find the second maximum value\n",
        "second_max_value = np.max(arr2)\n",
        "\n",
        "# print(\"Original array:\", arr2)\n",
        "print(\"Second maximum value:\", second_max_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUO0LLiws-Vh",
        "outputId": "72408e91-0c31-4f17-bae8-1ec96ded5b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second maximum value: 65470.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epTMvTwgtbv_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}